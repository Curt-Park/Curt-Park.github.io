---
layout: post
title: "[요약] MUNIT"
description: "Multimodal Unsupervised Image-to-Image Translation"
date: 2018-04-20
tags: [image to image translation]
comments: true
share: true
use_math: true
---

[Demo](https://youtu.be/ab64TWzWn40), [Paper](https://arxiv.org/abs/1804.04732)

**1. Limitation of existing methods:** 
Image-to-image translation의 경우, 보통 deterministic one-to-one mapping이거나 unimodal mapping이다.

**2. Goal:**
many-to-many cross-domain mapping을 해보자!

**3. Assumption:** 
- image에 대한 latent space는 content space와 style space로 decomposed 될 수 있다. 
- content space의 경우 서로 다른 도메인 사이에서 공유되고, style space의 경우 각 도메인마다 존재한다.  이렇게 가정한다면 source domain에서 얻은 content vector + target domain의 style vector로 원하는 형태의 target image를 얻을 수 있을것. (여기서 style vector는 random sampling일수도 있고, user-provided example일수도 있다.) 이때 content를 the underling spatial structure로 정의하고, 복잡한 prior distribution을 가지는 high-dimensional spatial map으로 가정한다. 또한 style code는 가우시안 분포를 띄는 low-dimensional vector라고 가정한다.

**4. Related works:**
- GAN
- Image-to-Image translation
- Style transfer
- Learning disentangled representation

**5. Model:**
논문 Fig2 참고

**6. Loss function:**
논문 (1) ~ (5) 참고. Bidirectional reconstruction loss (Image reconstruction + latent reconstruction)와 Adversarial loss가 합쳐진 형태.

**7. Theoretical Analysis: (some remarkable points)**
Joint distribution matching(when optimality is reached, we have $$p(x_1, x_{1\rightarrow2}) = p(x_{2\rightarrow1}, x_2))$$은 unsupervised image-to-image translation을 위한 중요한 제약사항이다. (CycleGAN에서 제안한 cycle consistency constraint로 이 제약사항을 만족시킬 수 있음) 허나, 이 제약사항을 너무 강제하게되면 model이 deterministic function이 된다. (AppendixA - 5에 증명) Multimodal image translation을 위해서는 cycle consistency를 다소 느슨하게 할 필요가 있음.
=> image를 target domain으로 translate하는 과정에 style code가 들어감으로써 이를 달성할 수 있음. original style code를 사용함으로써 target image를 다시 original image로 translate back 할 수 있다.

**8. Implementation (Autoencoder part):**
논문 Fig3 참고
discriminator로는 LSGAN의 것이 사용됨

**9. Experiment:**
(1) Paired supervision으로 학습된 BicycleGAN에 거의 근접한 퀄리티를 보임. 
(2) 양적 평가에서 CycleGAN, UNIT을 압도

**10. Conclusions:**
Multimodal unsupervised image-to-image translation을 위한 framework를 만들었다! 우리가 봐도 짱짱맨인듯. (양적 / 질적으로)

**11. Questions… (Things to study more)**
- Style encoder는 모든 domain에서 공유하는가?
- AdaIN의 입력으로 사용되는 z는 MLP의 출력인가?
- MLP의 구조는?
- AdaIN은 Batch normalization과 뭐가 다른가?
